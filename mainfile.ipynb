{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Lasse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "#---------- Library Imports ----------\n",
                "import torch\n",
                "import cv2\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "from torchvision import transforms\n",
                "import os\n",
                "import sequential_creator\n",
                "import glob\n",
                "from torchmetrics import MeanAbsolutePercentageError as MAPE\n",
                "import matplotlib as mpl\n",
                "import re\n",
                "import json\n",
                "from tqdm import tqdm\n",
                "import pytorch_lightning as pl\n",
                "from torch.utils.data import DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "%reload_ext autoreload"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "#---------- Personal python files imports ----------\n",
                "import load_lettuce_dataset\n",
                "import data_augmentation\n",
                "import model_and_training_files\n",
                "import lettuce_dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "#---------- Hyperparameters ----------\n",
                "batch_size = 16\n",
                "learning_rate = 1e-3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "#---------- Other parameters ----------\n",
                "augmented_dataset_size = 341 # Size of the augmented dataset, so if the original dataset contained 103 images, they would be augmented and made into 2000 images\n",
                "                              # One thing to note is that if this number is much bigger than the size of the original dataset, then they would most likely end up being duplicates, since there is not that many augmentations implemented at the moment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 341/341 [00:05<00:00, 66.51it/s]\n"
                    ]
                }
            ],
            "source": [
                "#---------- Load Lettuce Dataset ----------\n",
                "rgb_list, depth_list, fresh_weight_list, dry_weight_list = load_lettuce_dataset.load_all_images()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Augmenting RGB Images\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 341/341 [01:03<00:00,  5.35it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Amount of augmented images 341\n"
                    ]
                }
            ],
            "source": [
                "#---------- Augment Lettuce Dataset ----------\n",
                "depth_img_aug, rgb_imgs_aug, fresh_weight_GT, dry_weight_GT = data_augmentation.augment_data(rgb_images=rgb_list, depth_images=depth_list, fresh_weight_GT=fresh_weight_list, dry_weight_GT=dry_weight_list, amount_of_augmentated_images=augmented_dataset_size)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Size of images in the dataset:  (341, 4, 640, 480)  --> (Amount of images, total channels, img_w, img_h)\n",
                        "Size of images in the dataset:  (640, 480)\n",
                        "train, validation, test =  [255, 42, 44]\n"
                    ]
                }
            ],
            "source": [
                "#---------- Create data loaders ----------\n",
                "# Concatenate the depth and rgb images\n",
                "full_dataset = []\n",
                "full_dataset_labels = []\n",
                "for i in range(augmented_dataset_size):\n",
                "    depth_plus_rgb = np.concatenate((depth_img_aug[i], rgb_imgs_aug[i]), axis=0)\n",
                "    full_dataset.append(depth_plus_rgb)\n",
                "    #full_dataset.append([depth_img_aug[i], rgb_imgs_aug[i]])\n",
                "    full_dataset_labels.append([fresh_weight_GT[i], dry_weight_GT[i]])\n",
                "\n",
                "print(\"Size of images in the dataset: \", np.array(full_dataset).shape, \" --> (Amount of images, total channels, img_w, img_h)\")\n",
                "print(\"Size of images in the dataset: \", np.array(full_dataset[0][0]).shape)\n",
                "\n",
                "# Define the dataset\n",
                "dataset = lettuce_dataset.LettuceDataset(full_dataset, full_dataset_labels)\n",
                "\n",
                "# Split the dataset in train, validation and test\n",
                "splitted_data = lettuce_dataset.data_splittage(augmented_dataset_size, [75, 12.5, 12.5])\n",
                "print(\"train, validation, test = \", splitted_data)\n",
                "\n",
                "train_set, validation_set, test_set = torch.utils.data.random_split(dataset, splitted_data)\n",
                "#train_set, validation_set, test_set = torch.utils.data.random_split(dataset, [7500, 1250, 1250])\n",
                "\n",
                "# Create dataloaders for train, validation and test data\n",
                "train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle = True)\n",
                "validation_loader = DataLoader(dataset = validation_set, batch_size = batch_size, shuffle = True)\n",
                "test_loader = DataLoader(dataset = test_set, batch_size = batch_size, shuffle = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "#---------- Model Definition ----------\n",
                "# Code modified from Anders Glent Buch elective course Deep Neural Networks\n",
                "# Tip: dont forget to include activation layer (ReLu)\n",
                "\n",
                "def build_cnn_layer(in_channels, out_channels, kernal_size=3, stride=1, padding=1, \n",
                "                    use_batchnorm=True, pool=False):\n",
                "    '''\n",
                "    in_channels: input channels to 2d convolution layer\n",
                "    out_channels: ouput channels to 2d convolution layer\n",
                "    kernal_size: kernal size (refer torch conv2d)\n",
                "    stride: stride (refer torch conv2d)\n",
                "    padding: padding (refer torch conv2d)  \n",
                "    use_batchnorm: enable/disable batchnorm (refer torch BatchNorm2d)\n",
                "    pool: enable/disable pooling (refer torch MaxPool2D)\n",
                "\n",
                "    should return the built CNN layer\n",
                "    '''\n",
                "    return torch.nn.Sequential(\n",
                "        torch.nn.Conv2d(in_channels, out_channels, kernal_size, stride=stride, padding=padding),\n",
                "        torch.nn.ReLU(inplace=True),\n",
                "        torch.nn.BatchNorm2d(out_channels) if use_batchnorm else torch.nn.Identity(),\n",
                "        torch.nn.MaxPool2d(4, 4) if pool else torch.nn.Identity(),\n",
                "    )\n",
                "\n",
                "# Remember to flatten after convolution layers before its passed to linear layers\n",
                "# Also activation layer for final layers\n",
                "def build_cnn_model():\n",
                "    '''\n",
                "    pool: enable/disable pooling\n",
                "\n",
                "    should return built CNN model\n",
                "    '''\n",
                "    return torch.nn.Sequential(\n",
                "        # (B, 4, 640, 480) images\n",
                "        build_cnn_layer(4, 8, stride=1, pool=True),\n",
                "        build_cnn_layer(8, 16, stride=1, pool=True), \n",
                "        build_cnn_layer(16, 32, stride=1, pool=True),\n",
                "        torch.nn.Flatten(),\n",
                "        torch.nn.Linear(2240, 1000),\n",
                "        torch.nn.ReLU(True),\n",
                "        torch.nn.Linear(1000, 512),\n",
                "        torch.nn.ReLU(True),\n",
                "        torch.nn.BatchNorm1d(512), # (B, 512)\n",
                "        torch.nn.Linear(512, 2), # (B, 2) logits\n",
                "    )    \n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "#---------- Model declaration ----------\n",
                "model = build_cnn_model()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sequential(\n",
                        "  (0): Sequential(\n",
                        "    (0): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
                        "    (1): ReLU(inplace=True)\n",
                        "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
                        "  )\n",
                        "  (1): Sequential(\n",
                        "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
                        "    (1): ReLU(inplace=True)\n",
                        "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
                        "  )\n",
                        "  (2): Sequential(\n",
                        "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
                        "    (1): ReLU(inplace=True)\n",
                        "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
                        "  )\n",
                        "  (3): Flatten(start_dim=1, end_dim=-1)\n",
                        "  (4): Linear(in_features=2240, out_features=1000, bias=True)\n",
                        "  (5): ReLU(inplace=True)\n",
                        "  (6): Linear(in_features=1000, out_features=512, bias=True)\n",
                        "  (7): ReLU(inplace=True)\n",
                        "  (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "  (9): Linear(in_features=512, out_features=2, bias=True)\n",
                        ")\n"
                    ]
                }
            ],
            "source": [
                "print(model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Auto select gpus: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cuda available =  True\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "\n",
                        "  | Name      | Type                        | Params\n",
                        "----------------------------------------------------------\n",
                        "0 | model     | BiomassModel                | 2.8 M \n",
                        "1 | loss_func | MeanAbsolutePercentageError | 0     \n",
                        "----------------------------------------------------------\n",
                        "2.8 M     Trainable params\n",
                        "0         Non-trainable params\n",
                        "2.8 M     Total params\n",
                        "11.047    Total estimated model params size (MB)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 10: 100%|██████████| 19/19 [00:09<00:00,  2.01it/s, loss=0.716, v_num=13]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Testing DataLoader 0: 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
                        "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
                        "       Test metric             DataLoader 0\n",
                        "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
                        "        test_loss           0.8664084076881409\n",
                        "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[{'test_loss': 0.8664084076881409}]"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#---------- Training ----------\n",
                "print(\"Cuda available = \", torch.cuda.is_available())\n",
                "\n",
                "# Define the model with Pytorch Lightning\n",
                "model = model_and_training_files.BiomassModel(CNNmodel=model,\n",
                "                                                lr=learning_rate,\n",
                "                                                )\n",
                "\n",
                "trainer = model_and_training_files.get_trainer()    # gets the trainer (which is a class that takes the model and dataset)\n",
                "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader) # Train the model\n",
                "trainer.test(model, dataloaders=test_loader)\n",
                "\n",
                "#---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "ename": "MemoryError",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
                        "\u001b[1;32md:\\EITgit\\Biomass_Estimation\\mainfile.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EITgit/Biomass_Estimation/mainfile.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#------- Save the weights ----------\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/EITgit/Biomass_Estimation/mainfile.ipynb#Y103sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m torch\u001b[39m.\u001b[39;49msave(model, \u001b[39m\"\u001b[39;49m\u001b[39msaved_models/best_weights_V1.plk\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
                        "File \u001b[1;32mc:\\Users\\Lasse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:423\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    422\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 423\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    424\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[39melse\u001b[39;00m:\n",
                        "File \u001b[1;32mc:\\Users\\Lasse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:635\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    633\u001b[0m pickler \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mPickler(data_buf, protocol\u001b[39m=\u001b[39mpickle_protocol)\n\u001b[0;32m    634\u001b[0m pickler\u001b[39m.\u001b[39mpersistent_id \u001b[39m=\u001b[39m persistent_id\n\u001b[1;32m--> 635\u001b[0m pickler\u001b[39m.\u001b[39;49mdump(obj)\n\u001b[0;32m    636\u001b[0m data_value \u001b[39m=\u001b[39m data_buf\u001b[39m.\u001b[39mgetvalue()\n\u001b[0;32m    637\u001b[0m zip_file\u001b[39m.\u001b[39mwrite_record(\u001b[39m'\u001b[39m\u001b[39mdata.pkl\u001b[39m\u001b[39m'\u001b[39m, data_value, \u001b[39mlen\u001b[39m(data_value))\n",
                        "\u001b[1;31mMemoryError\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "#------- Save the weights ----------\n",
                "torch.save(model, \"saved_models/best_weights_V1.plk\") # Saves the regression head"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "ename": "RuntimeError",
                    "evalue": "PytorchStreamReader failed locating file data.pkl: file not found",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "\u001b[1;32md:\\EITgit\\Biomass_Estimation\\mainfile.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/EITgit/Biomass_Estimation/mainfile.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39msaved_models/best_weights_V1.plk\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EITgit/Biomass_Estimation/mainfile.ipynb#Y102sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#fresh_weight_GT, dry_weight_GT\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EITgit/Biomass_Estimation/mainfile.ipynb#Y102sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m imgidx \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m\n",
                        "File \u001b[1;32mc:\\Users\\Lasse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    787\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    788\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> 789\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m    790\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[0;32m    791\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
                        "File \u001b[1;32mc:\\Users\\Lasse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:1127\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1124\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfind_class(mod_name, name)\n\u001b[0;32m   1126\u001b[0m \u001b[39m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[39;00m\n\u001b[1;32m-> 1127\u001b[0m data_file \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(zip_file\u001b[39m.\u001b[39;49mget_record(pickle_file))\n\u001b[0;32m   1129\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1130\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n",
                        "\u001b[1;31mRuntimeError\u001b[0m: PytorchStreamReader failed locating file data.pkl: file not found"
                    ]
                }
            ],
            "source": [
                "model = torch.load(\"saved_models/best_weights_V1.plk\")\n",
                "#fresh_weight_GT, dry_weight_GT\n",
                "imgidx = 6\n",
                "pred = model.prediction(depth_img_aug[imgidx], rgb_imgs_aug[imgidx])\n",
                "print(pred)\n",
                "print(fresh_weight_GT[imgidx], dry_weight_GT[imgidx])\n",
                "loss = MAPE()\n",
                "true = torch.from_numpy(np.array([[fresh_weight_GT[imgidx], dry_weight_GT[imgidx]]]))\n",
                "print(loss(pred,true))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.0 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "3872e51830101b1d178418ab45f15963383a34a7de805094578585ef84da2345"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
