{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "#---------- Library Imports ----------\n",
                "import torch\n",
                "import cv2\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "from torchvision import transforms\n",
                "import os\n",
                "import sequential_creator\n",
                "import glob\n",
                "from torchmetrics import MeanAbsolutePercentageError as MAPE\n",
                "import matplotlib as mpl\n",
                "import re\n",
                "import json\n",
                "from tqdm import tqdm\n",
                "import pytorch_lightning as pl\n",
                "from torch.utils.data import DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "%reload_ext autoreload"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "#---------- Personal python files imports ----------\n",
                "import load_lettuce_dataset\n",
                "import data_augmentation\n",
                "import model_and_training_files\n",
                "import lettuce_dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "#---------- Hyperparameters ----------\n",
                "batch_size = 16\n",
                "learning_rate = 1e-3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "#---------- Other parameters ----------\n",
                "augmented_dataset_size = 20 # Size of the augmented dataset, so if the original dataset contained 103 images, they would be augmented and made into 2000 images\n",
                "                              # One thing to note is that if this number is much bigger than the size of the original dataset, then they would most likely end up being duplicates, since there is not that many augmentations implemented at the moment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 341/341 [01:48<00:00,  3.13it/s]\n"
                    ]
                }
            ],
            "source": [
                "#---------- Load Lettuce Dataset ----------\n",
                "rgb_list, depth_list, fresh_weight_list, dry_weight_list = load_lettuce_dataset.load_all_images()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Augmenting RGB Images\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 20/20 [00:00<00:00, 42.37it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Amount of augmented images 20\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "#---------- Augment Lettuce Dataset ----------\n",
                "depth_img_aug, rgb_imgs_aug, fresh_weight_GT, dry_weight_GT = data_augmentation.augment_data(rgb_images=rgb_list, depth_images=depth_list, fresh_weight_GT=fresh_weight_list, dry_weight_GT=dry_weight_list, amount_of_augmentated_images=augmented_dataset_size)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Size of images in the dataset:  (20, 6, 224, 224)  --> (Amount of images, total channels, img_w, img_h)\n",
                        "Size of images in the dataset:  (224, 224)\n",
                        "train, validation, test =  [15, 2, 3]\n"
                    ]
                }
            ],
            "source": [
                "#---------- Create data loaders ----------\n",
                "# Concatenate the depth and rgb images\n",
                "full_dataset = []\n",
                "full_dataset_labels = []\n",
                "for i in range(augmented_dataset_size):\n",
                "    depth_plus_rgb = np.concatenate((depth_img_aug[i], rgb_imgs_aug[i]), axis=0)\n",
                "    full_dataset.append(depth_plus_rgb)\n",
                "    #full_dataset.append([depth_img_aug[i], rgb_imgs_aug[i]])\n",
                "    full_dataset_labels.append([fresh_weight_GT[i], dry_weight_GT[i]])\n",
                "\n",
                "print(\"Size of images in the dataset: \", np.array(full_dataset).shape, \" --> (Amount of images, total channels, img_w, img_h)\")\n",
                "print(\"Size of images in the dataset: \", np.array(full_dataset[0][0]).shape)\n",
                "\n",
                "# Define the dataset\n",
                "dataset = lettuce_dataset.LettuceDataset(full_dataset, full_dataset_labels)\n",
                "\n",
                "# Split the dataset in train, validation and test\n",
                "splitted_data = lettuce_dataset.data_splittage(augmented_dataset_size, [75, 12.5, 12.5])\n",
                "print(\"train, validation, test = \", splitted_data)\n",
                "\n",
                "train_set, validation_set, test_set = torch.utils.data.random_split(dataset, splitted_data)\n",
                "#train_set, validation_set, test_set = torch.utils.data.random_split(dataset, [7500, 1250, 1250])\n",
                "\n",
                "# Create dataloaders for train, validation and test data\n",
                "train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle = True)\n",
                "validation_loader = DataLoader(dataset = validation_set, batch_size = batch_size, shuffle = True)\n",
                "test_loader = DataLoader(dataset = test_set, batch_size = batch_size, shuffle = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Using cache found in C:\\Users\\Lasse/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sequential(\n",
                        "  (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
                        "  (1): ReLU()\n",
                        "  (2): Linear(in_features=1000, out_features=500, bias=True)\n",
                        "  (3): ReLU()\n",
                        "  (4): Linear(in_features=500, out_features=250, bias=True)\n",
                        "  (5): ReLU()\n",
                        "  (6): Linear(in_features=250, out_features=2, bias=True)\n",
                        "  (7): ReLU()\n",
                        ")\n"
                    ]
                }
            ],
            "source": [
                "#---------- Model Definition ----------\n",
                "# Code modified from Anders Glent Buch elective course Deep Neural Networks\n",
                "# Tip: dont forget to include activation layer (ReLu)\n",
                "\n",
                "def build_cnn_layer(in_channels, out_channels, kernal_size=3, stride=1, padding=1, \n",
                "                    use_batchnorm=True, pool=False):\n",
                "    '''\n",
                "    in_channels: input channels to 2d convolution layer\n",
                "    out_channels: ouput channels to 2d convolution layer\n",
                "    kernal_size: kernal size (refer torch conv2d)\n",
                "    stride: stride (refer torch conv2d)\n",
                "    padding: padding (refer torch conv2d)  \n",
                "    use_batchnorm: enable/disable batchnorm (refer torch BatchNorm2d)\n",
                "    pool: enable/disable pooling (refer torch MaxPool2D)\n",
                "\n",
                "    should return the built CNN layer\n",
                "    '''\n",
                "    return torch.nn.Sequential(\n",
                "        torch.nn.Conv2d(in_channels, out_channels, kernal_size, stride=stride, padding=padding),\n",
                "        torch.nn.ReLU(inplace=True),\n",
                "        torch.nn.BatchNorm2d(out_channels) if use_batchnorm else torch.nn.Identity(),\n",
                "        torch.nn.MaxPool2d(2, 2) if pool else torch.nn.Identity(),\n",
                "    )\n",
                "\n",
                "# Remember to flatten after convolution layers before its passed to linear layers\n",
                "# Also activation layer for final layers\n",
                "def build_cnn_model(pool=False):\n",
                "    '''\n",
                "    pool: enable/disable pooling\n",
                "\n",
                "    should return built CNN model\n",
                "    '''\n",
                "    nf = 32\n",
                "    s = 1 if pool else 2\n",
                "    return torch.nn.Sequential(\n",
                "        # (B, 3, 32, 32) images\n",
                "        build_cnn_layer(3, nf),  # (B, nf, 32, 32)\n",
                "        build_cnn_layer(nf, 2 * nf, stride=s, pool=pool),  # (B, 2 * nf, 16, 16)\n",
                "        build_cnn_layer(2 * nf, 4 * nf, stride=s, pool=pool),  # (B, 4 * nf, 8, 8)\n",
                "        build_cnn_layer(4 * nf, 8 * nf, stride=s, pool=pool),  # (B, 8 * nf, 4, 4)\n",
                "        torch.nn.Flatten(), # (B, 8 * nf * 4 * 4)\n",
                "        torch.nn.Linear(8 * nf * 4 * 4, 512), torch.nn.ReLU(True), torch.nn.BatchNorm1d(512), # (B, 512)\n",
                "        torch.nn.Linear(512, 10), # (B, 10) logits\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#---------- Model declaration ----------\n",
                "model = build_cnn_model()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Auto select gpus: [0]\n",
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cuda available =  True\n",
                        "1\n",
                        "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
                        "2\n",
                        "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "3\n",
                        "ReLU(inplace=True)\n",
                        "4\n",
                        "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
                        "5\n",
                        "Sequential(\n",
                        "  (0): Bottleneck(\n",
                        "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "    (downsample): Sequential(\n",
                        "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    )\n",
                        "  )\n",
                        "  (1): Bottleneck(\n",
                        "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (2): Bottleneck(\n",
                        "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        ")\n",
                        "6\n",
                        "Sequential(\n",
                        "  (0): Bottleneck(\n",
                        "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "    (downsample): Sequential(\n",
                        "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
                        "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    )\n",
                        "  )\n",
                        "  (1): Bottleneck(\n",
                        "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (2): Bottleneck(\n",
                        "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (3): Bottleneck(\n",
                        "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        ")\n",
                        "7\n",
                        "Sequential(\n",
                        "  (0): Bottleneck(\n",
                        "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "    (downsample): Sequential(\n",
                        "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
                        "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    )\n",
                        "  )\n",
                        "  (1): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (2): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (3): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (4): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (5): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (6): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (7): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (8): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (9): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (10): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (11): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (12): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (13): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (14): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (15): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (16): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (17): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (18): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (19): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (20): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (21): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (22): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        ")\n",
                        "8\n",
                        "Sequential(\n",
                        "  (0): Bottleneck(\n",
                        "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "    (downsample): Sequential(\n",
                        "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
                        "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    )\n",
                        "  )\n",
                        "  (1): Bottleneck(\n",
                        "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        "  (2): Bottleneck(\n",
                        "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
                        "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                        "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                        "    (relu): ReLU(inplace=True)\n",
                        "  )\n",
                        ")\n",
                        "9\n",
                        "AdaptiveAvgPool2d(output_size=(1, 1))\n",
                        "10\n",
                        "Linear(in_features=2048, out_features=1000, bias=True)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "\n",
                        "  | Name   | Type       | Params\n",
                        "--------------------------------------\n",
                        "0 | layers | Sequential | 2.6 M \n",
                        "1 | Resnet | ResNet     | 44.5 M\n",
                        "--------------------------------------\n",
                        "45.7 M    Trainable params\n",
                        "1.4 M     Non-trainable params\n",
                        "47.2 M    Total params\n",
                        "188.706   Total estimated model params size (MB)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 199: 100%|██████████| 4/4 [00:03<00:00,  1.31it/s, loss=0.539, v_num=11]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 199: 100%|██████████| 4/4 [00:12<00:00,  3.14s/it, loss=0.539, v_num=11]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
                        "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
                        "       Test metric             DataLoader 0\n",
                        "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
                        "        test_loss           1.1976007223129272\n",
                        "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
                    ]
                }
            ],
            "source": [
                "#---------- Training ----------\n",
                "print(\"Cuda available = \", torch.cuda.is_available())\n",
                "\n",
                "# Define the model with Pytorch Lightning\n",
                "model = model_and_training_files.BiomassModel(model=model,\n",
                "                                                lr=learning_rate,\n",
                "                                                )\n",
                "\n",
                "trainer = model_and_training_files.get_trainer()    # gets the trainer (which is a class that takes the model and dataset)\n",
                "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader) # Train the model\n",
                "trainer.test(model, dataloaders=test_loader)\n",
                "\n",
                "#---------- Save the weights ----------\n",
                "torch.save(model, \"saved_models/best_weights_V1.plk\") # Saves the regression head"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([[0.0724, 0.0000]])\n",
                        "27.9 1.76\n",
                        "tensor(0.9987)\n"
                    ]
                }
            ],
            "source": [
                "model = torch.load(\"saved_models/best_weights_V1.plk\")\n",
                "#fresh_weight_GT, dry_weight_GT\n",
                "imgidx = 6\n",
                "pred = model.prediction(depth_img_aug[imgidx], rgb_imgs_aug[imgidx])\n",
                "print(pred)\n",
                "print(fresh_weight_GT[imgidx], dry_weight_GT[imgidx])\n",
                "loss = MAPE()\n",
                "true = torch.from_numpy(np.array([[fresh_weight_GT[imgidx], dry_weight_GT[imgidx]]]))\n",
                "print(loss(pred,true))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.8 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "a569b293e0c6f5b8d5c7b027c77c352cc6b942ffb1eb577576f1f20f41e9121b"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
