{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "#---------- Library Imports ----------\n",
                "import torch\n",
                "import cv2\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "from torchvision import transforms\n",
                "import os\n",
                "import sequential_creator\n",
                "import glob\n",
                "from torchmetrics import MeanAbsolutePercentageError as MAPE\n",
                "import matplotlib as mpl\n",
                "import re\n",
                "import json\n",
                "from tqdm import tqdm\n",
                "import pytorch_lightning as pl\n",
                "from torch.utils.data import DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "#%reload_ext autoreload"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "#---------- Personal python files imports ----------\n",
                "import load_lettuce_dataset\n",
                "import data_augmentation\n",
                "import model_and_training_files\n",
                "import lettuce_dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "#---------- Hyperparameters ----------\n",
                "batch_size = 16\n",
                "learning_rate = 1e-3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "#---------- Other parameters ----------\n",
                "augmented_dataset_size = 50 # Size of the augmented dataset, so if the original dataset contained 103 images, they would be augmented and made into 2000 images\n",
                "                              # One thing to note is that if this number is much bigger than the size of the original dataset, then they would most likely end up being duplicates, since there is not that many augmentations implemented at the moment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 341/341 [02:35<00:00,  2.19it/s]\n"
                    ]
                }
            ],
            "source": [
                "#---------- Load Lettuce Dataset ----------\n",
                "rgb_list, depth_list, fresh_weight_list, dry_weight_list = load_lettuce_dataset.load_all_images()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Augmenting RGB Images\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 50/50 [00:29<00:00,  1.67it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Amount of augmented images 50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "#---------- Augment Lettuce Dataset ----------\n",
                "depth_img_aug, rgb_imgs_aug, fresh_weight_GT, dry_weight_GT = data_augmentation.augment_data(rgb_images=rgb_list, depth_images=depth_list, fresh_weight_GT=fresh_weight_list, dry_weight_GT=dry_weight_list, amount_of_augmentated_images=augmented_dataset_size)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Size of images in the dataset:  (1080, 1920, 3)\n",
                        "train, validation, test =  [37, 6, 7]\n"
                    ]
                }
            ],
            "source": [
                "#---------- Create data loaders ----------\n",
                "# Concatenate the depth and rgb images\n",
                "full_dataset = []\n",
                "full_dataset_labels = []\n",
                "for i in range(augmented_dataset_size):\n",
                "    full_dataset.append([depth_img_aug[i], rgb_imgs_aug[i]])\n",
                "    full_dataset_labels.append([fresh_weight_GT[i], dry_weight_GT[i]])\n",
                "\n",
                "print(\"Size of images in the dataset: \", np.array(full_dataset[0][0]).shape)\n",
                "\n",
                "# Define the dataset\n",
                "dataset = lettuce_dataset.LettuceDataset(full_dataset, full_dataset_labels)\n",
                "\n",
                "# Split the dataset in train, validation and test\n",
                "splitted_data = lettuce_dataset.data_splittage(augmented_dataset_size, [75, 12.5, 12.5])\n",
                "print(\"train, validation, test = \", splitted_data)\n",
                "\n",
                "train_set, validation_set, test_set = torch.utils.data.random_split(dataset, splitted_data)\n",
                "#train_set, validation_set, test_set = torch.utils.data.random_split(dataset, [7500, 1250, 1250])\n",
                "\n",
                "# Create dataloaders for train, validation and test data\n",
                "train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle = True)\n",
                "validation_loader = DataLoader(dataset = validation_set, batch_size = batch_size, shuffle = True)\n",
                "test_loader = DataLoader(dataset = test_set, batch_size = batch_size, shuffle = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Using cache found in C:\\Users\\Ulric/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
                        "Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to C:\\Users\\Ulric/.cache\\torch\\hub\\checkpoints\\resnet101-cd907fc2.pth\n",
                        "100%|██████████| 171M/171M [00:15<00:00, 11.3MB/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sequential(\n",
                        "  (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
                        "  (1): ReLU()\n",
                        "  (2): Linear(in_features=1000, out_features=500, bias=True)\n",
                        "  (3): ReLU()\n",
                        "  (4): Linear(in_features=500, out_features=250, bias=True)\n",
                        "  (5): ReLU()\n",
                        "  (6): Linear(in_features=250, out_features=2, bias=True)\n",
                        "  (7): ReLU()\n",
                        ")\n"
                    ]
                }
            ],
            "source": [
                "#---------- Model Definition ----------\n",
                "# Load ResNet Backbone (Pretrained Model)\n",
                "resnet_version = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
                "# We can reuse the same resnet model since weights are not updated and both RGB and Depth are same format\n",
                "resnet_model_RGB_and_depth = torch.hub.load('pytorch/vision:v0.10.0', resnet_version[3], weights=\"ResNet101_Weights.DEFAULT\")\n",
                "resnet_model_RGB_and_depth.eval() # We don't want the resnet to update (Sets a flag, kind of a switch to turn off gradient computation)\n",
                "\n",
                "# Create Regression Head\n",
                "head_input_neurons = 2000 # 1000 output feature vector from RGB resnet and 1000 from depth resnet\n",
                "head_hidden = [1000, 500, 250]\n",
                "head_output_neurons = 2\n",
                "head_activation = torch.nn.ReLU()\n",
                "regression_head = sequential_creator.make_model(input=head_input_neurons, hidden=head_hidden, output=head_output_neurons, activation=head_activation)\n",
                "\n",
                "print(regression_head)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: False, used: False\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "Missing logger folder: logs/my_model\n",
                        "\n",
                        "  | Name   | Type       | Params\n",
                        "--------------------------------------\n",
                        "0 | layers | Sequential | 2.6 M \n",
                        "1 | Resnet | ResNet     | 44.5 M\n",
                        "--------------------------------------\n",
                        "47.2 M    Trainable params\n",
                        "0         Non-trainable params\n",
                        "47.2 M    Total params\n",
                        "188.706   Total estimated model params size (MB)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "False\n",
                        "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "ename": "AttributeError",
                    "evalue": "'list' object has no attribute 'shape'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn [28], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[39m=\u001b[39m model_and_training_files\u001b[39m.\u001b[39mBiomassModel(regression_head\u001b[39m=\u001b[39mregression_head, \n\u001b[0;32m      6\u001b[0m                                                 resnet_model_RGB_and_depth\u001b[39m=\u001b[39mresnet_model_RGB_and_depth,\n\u001b[0;32m      7\u001b[0m                                                 lr\u001b[39m=\u001b[39mlearning_rate,\n\u001b[0;32m      8\u001b[0m                                                 )\n\u001b[0;32m     10\u001b[0m trainer \u001b[39m=\u001b[39m model_and_training_files\u001b[39m.\u001b[39mget_trainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)    \u001b[39m# gets the trainer (which is a class that takes the model and dataset)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, train_dataloaders\u001b[39m=\u001b[39;49mtrain_loader, val_dataloaders\u001b[39m=\u001b[39;49mvalidation_loader) \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m     12\u001b[0m trainer\u001b[39m.\u001b[39mtest(model, dataloaders\u001b[39m=\u001b[39mtest_loader)\n\u001b[0;32m     14\u001b[0m \u001b[39m#---------- Save the weights ----------\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:579\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    578\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m--> 579\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    580\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    581\u001b[0m )\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:621\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    614\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    615\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    616\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    617\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    619\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    620\u001b[0m )\n\u001b[1;32m--> 621\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[0;32m    623\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    624\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1058\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1056\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[1;32m-> 1058\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m   1060\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1061\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1137\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[0;32m   1136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1137\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1150\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_training_routine()\n\u001b[0;32m   1149\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1150\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[0;32m   1152\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1222\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m-> 1222\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1224\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1226\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    151\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[1;32m--> 152\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[0;32m    154\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:137\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[0;32m    136\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n\u001b[0;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:234\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[0;32m    225\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39m    the outputs of the step\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 234\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(hook_name, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[0;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1440\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1440\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1442\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1443\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[0;32m    389\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mvalidation_step(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\Ulric\\OneDrive - Syddansk Universitet\\9. Semester\\EIT\\NN_1st_github\\Biomass_Estimation\\model_and_training_files.py:52\u001b[0m, in \u001b[0;36mBiomassModel.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidation_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m     50\u001b[0m     depth_rgb, weights \u001b[39m=\u001b[39m batch  \u001b[39m# weights fresh , dry\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[39mprint\u001b[39m(depth_rgb\u001b[39m.\u001b[39;49mshape)\n\u001b[0;32m     53\u001b[0m     \u001b[39m#split rgb_depth to rgb and depth\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     rgb_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresnet_rgb(rgb)\n",
                        "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
                    ]
                }
            ],
            "source": [
                "#---------- Training ----------\n",
                "print(torch.cuda.is_available())\n",
                "\n",
                "# Define the model with Pytorch Lightning\n",
                "model = model_and_training_files.BiomassModel(regression_head=regression_head, \n",
                "                                                resnet_model_RGB_and_depth=resnet_model_RGB_and_depth,\n",
                "                                                lr=learning_rate,\n",
                "                                                )\n",
                "\n",
                "trainer = model_and_training_files.get_trainer(max_epochs=1)    # gets the trainer (which is a class that takes the model and dataset)\n",
                "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader) # Train the model\n",
                "trainer.test(model, dataloaders=test_loader)\n",
                "\n",
                "#---------- Save the weights ----------\n",
                "torch.save(model, \"saved_models/best_weights_V1.plk\") # Saves the regression head"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.8 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "a569b293e0c6f5b8d5c7b027c77c352cc6b942ffb1eb577576f1f20f41e9121b"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
